{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='1'),\n",
       "  AIMessage(content='1'),\n",
       "  HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4,  # 대화 기록을 4개까지만 저장\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "\n",
    "# 현재 대화 상태를 나타내는 inputs 인자를 포함하여 메모리 변수를 불러옵니다.\n",
    "# 여기서는 예시를 위해 빈 딕셔너리를 사용합니다. 실제 사용 시에는 현재 대화 상태에 대한 정보를 포함해야 합니다.\n",
    "current_inputs = {}\n",
    "memory.load_memory_variables(current_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message(5, 5)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"안녕하세요! 저는 스타트업 스테이션 강사 이호진 입니다. 저는 서울에 살아요.\", \"서울에 산다는 것은 너무 행복합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"또한, 서울은 여러 장소들이 아릅답습니다.\", \"그래서 가보고 싶은 곳이 너무 많습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'The human greets the AI in Korean and introduces themselves as a startup station instructor living in Seoul. The AI responds that living in Seoul brings great happiness because there are so many amazing places to visit, making them want to explore even more.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='안녕하세요! 저는 이호진 입니다. 저는 서울에 살아요.'),\n",
       "  AIMessage(content='서울에 산다는 것은 너무 행복합니다.')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"안녕하세요! 저는 이호진 입니다. 저는 서울에 살아요.\", \"서울에 산다는 것은 너무 행복합니다.\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"또한, 서울은 여러 장소들이 아릅답습니다.\", \"그래서 가보고 싶은 곳이 너무 많습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='안녕하세요! 저는 이호진 입니다. 저는 서울에 살아요.'),\n",
       "  AIMessage(content='서울에 산다는 것은 너무 행복합니다.'),\n",
       "  HumanMessage(content='또한, 서울은 여러 장소들이 아릅답습니다.'),\n",
       "  AIMessage(content='그래서 가보고 싶은 곳이 너무 많습니다!')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"서울에서 볼라디보스톡까지 얼마나 걸리나요?\", \"음.. 잘 모르겠습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI in Korean and introduces themselves as Lee Hojin living in Seoul.'),\n",
       "  AIMessage(content='서울에 산다는 것은 너무 행복합니다.'),\n",
       "  HumanMessage(content='또한, 서울은 여러 장소들이 아릅답습니다.'),\n",
       "  AIMessage(content='그래서 가보고 싶은 곳이 너무 많습니다!'),\n",
       "  HumanMessage(content='서울에서 볼라디보스톡까지 얼마나 걸리나요?'),\n",
       "  AIMessage(content='음.. 잘 모르겠습니다.')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"서울에서 오스트리아 고사우까지 얼마나 걸리나요?\", \"음.. 잘 모르겠습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human greets the AI in Korean and introduces themselves as Lee Hojin living in Seoul. The AI expresses happiness at living in Seoul, and the human agrees, mentioning that Seoul has many amazing places.'),\n",
       "  AIMessage(content='그래서 가보고 싶은 곳이 너무 많습니다!'),\n",
       "  HumanMessage(content='서울에서 볼라디보스톡까지 얼마나 걸리나요?'),\n",
       "  AIMessage(content='음.. 잘 모르겠습니다.'),\n",
       "  HumanMessage(content='서울에서 오스트리아 고사우까지 얼마나 걸리나요?'),\n",
       "  AIMessage(content='음.. 잘 모르겠습니다.')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conversation Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(\"What is the capital of France?\", \"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\" : \"What is France\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"저는 스타트업캠퍼스 개발과정 강사 이호진입니다.\", \"제가 가진 지식을 공유하는 것은 너무 재밋습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\" : \"스타트업캠퍼스 개발과정 강사 이호진 좋아하는 것은?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On 이호진: 이호진 is a 개발과정 강사. 이호진 is a 스타트업캠퍼스. 이호진 is a 강사. 이호진 취미는 코딩. 이호진 취미는 음악 감상.')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이호진에 대한 정보 추가\n",
    "add_message(\"저는 스타트업캠퍼스 개발과정 강사 이호진입니다.\", \"이호진은 개발을 가르치는 것을 좋아합니다.\")\n",
    "add_message(\"이호진의 취미는 코딩과 음악 감상입니다.\", \"이호진은 여가 시간에 코딩을 하거나 음악을 듣습니다.\")\n",
    "\n",
    "# 정보 요청\n",
    "memory.load_memory_variables({\"input\" : \"스타트업캠퍼스 개발과정 강사 이호진 좋아하는 것은?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름은 이호진 입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 이호진님. 만나서 반가워요! 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 이호진 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m나는 서울에서 살고 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'서울은 대한민국의 수도이자 가장 큰 도시로서 문화, 역사, 쇼핑, 음식 등 다양한 즐길 거리가 많은 도시입니다. 서울에서는 한국 전통 문화를 체험할 수 있는 궁궐이나 사찰, 현대적인 건축물과 쇼핑몰, 다양한 음식을 맛볼 수 있는 레스토랑 등 다양한 즐길 거리가 있습니다. 또한 대중교통이 잘 발달해 있어 이동이 편리하고 안전한 도시이기도 합니다. 서울에서는 다양한 문화 행사나 축제도 많이 열리므로 즐거운 시간을 보낼 수 있습니다. 서울에서의 생활은 항상 새로운 경험과 발견이 기다리고 있어 흥미로운 도시입니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나는 서울에서 살고 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름이 무엇이니?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송합니다, 저는 당신의 이름을 알 수 없습니다. 당신의 이름을 알려주시겠어요?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름이 무엇이니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름은 이호진 입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 이호진님. 만나서 반가워요! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 이호진 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름이 무엇이니?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송합니다, 저는 당신의 이름을 알 수 없습니다. 당신의 이름을 알려주시겠어요?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름이 무엇이니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human introduces themselves as Lee Hojin. The AI responds in Korean, greeting Lee Hojin and asking how it can help.\\nHuman: 내 이름이 무엇이니?\\nAI: 죄송합니다, 저는 당신의 이름을 알 수 없습니다. 당신의 이름을 알려주시겠어요?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human:내 이름은 이호진 입니다.\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 이호진님. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 이호진 입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: 내 이름은 이호진 입니다.\n",
      "AI: 안녕하세요, 이호진님. 무엇을 도와드릴까요?\n",
      "    Human:나는 서울에서 살고 있습니다.\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그렇군요, 서울은 정말 멋진 도시입니다. 무엇이 필요하신가요? 부동산 정보나 관광지 추천 등 도와드릴 수 있는 것이 있나요?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"나는 서울에서 살고 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    System: The human introduces themselves as 이호진.\n",
      "AI: 안녕하세요, 이호진님. 무엇을 도와드릴까요?\n",
      "Human: 나는 서울에서 살고 있습니다.\n",
      "AI: 그렇군요, 서울은 정말 멋진 도시입니다. 무엇이 필요하신가요? 부동산 정보나 관광지 추천 등 도와드릴 수 있는 것이 있나요?\n",
      "    Human:내 이름이 무엇이니?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI: 죄송합니다, 이호진님. 제가 이름을 알 수 있는 방법은 없습니다. 어떤 도움이 필요하신가요?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름이 무엇이니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'System: The human introduces themselves as 이호진. The AI greets 이호진 and asks how it can help. 이호진 mentions living in Seoul. The AI acknowledges Seoul as a great city and offers assistance with real estate information or tourist recommendations.\\nHuman: 내 이름이 무엇이니?\\nAI: AI: 죄송합니다, 이호진님. 제가 이름을 알 수 있는 방법은 없습니다. 어떤 도움이 필요하신가요?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: 내 이름은 이호진 입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 이호진님. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 이호진 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LCEL Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Hojin Lee, it's nice to meet you too! How can I assist you today?\"\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Hello, My name is Hojin Lee, Nice to meet you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, you introduced yourself as Hojin Lee. How can I assist you, Hojin?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Do you know my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "class MovieEmojiMemoryManager:\n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory\n",
    "\n",
    "    def load_memory(self, _=None):\n",
    "        return self.memory.load_memory_variables({}).get(\"history\", [])\n",
    "\n",
    "    def save_memory(self, question, emoji):\n",
    "        self.memory.save_context({\"input\": question}, {\"output\": emoji})\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=120, return_messages=True)\n",
    "memory_manager = MovieEmojiMemoryManager(memory)\n",
    "\n",
    "emoji_response = {\n",
    "    \"탑건\": \"🛩️👨‍✈️🔥\",\n",
    "    \"매트릭스\": \"💊💻🕶️\",\n",
    "    \"터미네이터\": \"🤖🕰️🔫\",\n",
    "    \"해리포터\": \"🧙‍♂️🪄⚡\",\n",
    "    \"아메리칸 셰프\": \"👨‍🍳🍲🔪\",\n",
    "    \"범죄도시\": \"🔫🚓💰\",\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"영화 제목을 알려주시면, 그 영화를 대표하는 세 개의 이모티콘으로 응답해 드립니다.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=memory_manager.load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(movie_title):\n",
    "    question = f\"{movie_title}에 대한 세 개의 이모지는 무엇인가요?\"\n",
    "    selected_emoji = emoji_response.get(movie_title, \"❓❓❓\")\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory_manager.save_memory(question, selected_emoji)\n",
    "    print(f\"질문: {question}\\n응답: {selected_emoji}\")\n",
    "    \n",
    "    print(\"현재 메모리 상태:\", memory_manager.load_memory())\n",
    "\n",
    "\n",
    "def get_asked_movies():\n",
    "    history_data = memory_manager.load_memory()\n",
    "    if not history_data:\n",
    "        print(\"질문한 영화가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    movies_info = []\n",
    "    for i in range(0, len(history_data), 2):\n",
    "        # 질문 내용이 저장된 객체의 속성을 확인합니다.\n",
    "        question_item = history_data[i]\n",
    "        if hasattr(question_item, 'content'):\n",
    "            question_content = question_item.content\n",
    "            # \"에 대한 세 개의 이모지는 무엇인가요?\" 포함 여부를 확인합니다.\n",
    "            if \"에 대한 세 개의 이모지는 무엇인가요?\" in question_content:\n",
    "                movie_title = question_content.split(\"에 대한 세 개의 이모지는 무엇인가요?\")[0].strip()\n",
    "                # 다음 객체에서 응답(이모지)을 확인합니다.\n",
    "                if i+1 < len(history_data) and hasattr(history_data[i + 1], 'content'):\n",
    "                    emoji_response = history_data[i + 1].content\n",
    "                else:\n",
    "                    emoji_response = \"❓❓❓\"\n",
    "                movies_info.append(f\"영화: {movie_title}, 이모지: {emoji_response}\")\n",
    "\n",
    "    if movies_info:\n",
    "        print(\"\\n\".join(movies_info))\n",
    "    else:\n",
    "        print(\"질문한 영화 정보를 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 아메리칸 셰프에 대한 세 개의 이모지는 무엇인가요?\n",
      "응답: 👨‍🍳🍲🔪\n",
      "현재 메모리 상태: [HumanMessage(content='매트릭스에 대한 세 개의 이모지는 무엇인가요?'), AIMessage(content='💊💻🕶️'), HumanMessage(content='아메리칸 셰프에 대한 세 개의 이모지는 무엇인가요?'), AIMessage(content='👨\\u200d🍳🍲🔪')]\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"아메리칸 셰프\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 해리포터에 대한 세 개의 이모지는 무엇인가요?\n",
      "응답: 🧙‍♂️🪄⚡\n",
      "현재 메모리 상태: [SystemMessage(content='The human asks what three emojis represent \"The Matrix.\"'), AIMessage(content='💊💻🕶️'), HumanMessage(content='아메리칸 셰프에 대한 세 개의 이모지는 무엇인가요?'), AIMessage(content='👨\\u200d🍳🍲🔪'), HumanMessage(content='해리포터에 대한 세 개의 이모지는 무엇인가요?'), AIMessage(content='🧙\\u200d♂️🪄⚡')]\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"해리포터\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화: 아메리칸 셰프, 이모지: 👨‍🍳🍲🔪\n",
      "영화: 해리포터, 이모지: 🧙‍♂️🪄⚡\n"
     ]
    }
   ],
   "source": [
    "get_asked_movies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-yIjbGwu1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
