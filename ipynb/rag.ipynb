{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../files/chapter_one.txt\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../files/chapter_one.pdf\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.txt\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.pdf\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.docx\")\n",
    "\n",
    "len(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.docx\")\n",
    "\n",
    "len(loader.load_and_split(text_splitter=splitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "vector = embedder.embed_query(\"Hello, world!\")\n",
    "\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Created a chunk of size 963, which is longer than the specified 600\n",
      "Created a chunk of size 774, which is longer than the specified 600\n",
      "Created a chunk of size 954, which is longer than the specified 600\n",
      "Created a chunk of size 922, which is longer than the specified 600\n",
      "Created a chunk of size 1168, which is longer than the specified 600\n",
      "Created a chunk of size 821, which is longer than the specified 600\n",
      "Created a chunk of size 700, which is longer than the specified 600\n",
      "Created a chunk of size 745, which is longer than the specified 600\n",
      "Created a chunk of size 735, which is longer than the specified 600\n",
      "Created a chunk of size 1110, which is longer than the specified 600\n",
      "Created a chunk of size 991, which is longer than the specified 600\n",
      "Created a chunk of size 990, which is longer than the specified 600\n",
      "Created a chunk of size 1741, which is longer than the specified 600\n",
      "Created a chunk of size 2001, which is longer than the specified 600\n",
      "Created a chunk of size 1900, which is longer than the specified 600\n",
      "Created a chunk of size 1130, which is longer than the specified 600\n",
      "Created a chunk of size 1799, which is longer than the specified 600\n",
      "Created a chunk of size 1690, which is longer than the specified 600\n",
      "Created a chunk of size 2364, which is longer than the specified 600\n",
      "Created a chunk of size 930, which is longer than the specified 600\n",
      "Created a chunk of size 1022, which is longer than the specified 600\n",
      "Created a chunk of size 1260, which is longer than the specified 600\n",
      "Created a chunk of size 795, which is longer than the specified 600\n",
      "Created a chunk of size 1293, which is longer than the specified 600\n",
      "Created a chunk of size 649, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "cache_dir = LocalFileStore(\"/Users/hojin/Desktop/GPT/.cache/\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"where does winston live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(\"where does winston live\")\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(\"where does winston live\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Created a chunk of size 963, which is longer than the specified 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 774, which is longer than the specified 600\n",
      "Created a chunk of size 954, which is longer than the specified 600\n",
      "Created a chunk of size 922, which is longer than the specified 600\n",
      "Created a chunk of size 1168, which is longer than the specified 600\n",
      "Created a chunk of size 821, which is longer than the specified 600\n",
      "Created a chunk of size 700, which is longer than the specified 600\n",
      "Created a chunk of size 745, which is longer than the specified 600\n",
      "Created a chunk of size 735, which is longer than the specified 600\n",
      "Created a chunk of size 1110, which is longer than the specified 600\n",
      "Created a chunk of size 991, which is longer than the specified 600\n",
      "Created a chunk of size 990, which is longer than the specified 600\n",
      "Created a chunk of size 1182, which is longer than the specified 600\n",
      "Created a chunk of size 1491, which is longer than the specified 600\n",
      "Created a chunk of size 1401, which is longer than the specified 600\n",
      "Created a chunk of size 1130, which is longer than the specified 600\n",
      "Created a chunk of size 1326, which is longer than the specified 600\n",
      "Created a chunk of size 1449, which is longer than the specified 600\n",
      "Created a chunk of size 1364, which is longer than the specified 600\n",
      "Created a chunk of size 999, which is longer than the specified 600\n",
      "Created a chunk of size 930, which is longer than the specified 600\n",
      "Created a chunk of size 1022, which is longer than the specified 600\n",
      "Created a chunk of size 1260, which is longer than the specified 600\n",
      "Created a chunk of size 795, which is longer than the specified 600\n",
      "Created a chunk of size 1293, which is longer than the specified 600\n",
      "Created a chunk of size 649, which is longer than the specified 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston Smith lives in Victory Mansions.')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"../.cache\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriver,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "chain.invoke(\"Where does Winston live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building located in London. It is described as having glass doors through which Winston Smith enters. The building has a hallway that smells of boiled cabbage and old rag mats. On one end of the hallway, there is a large colored poster depicting the face of a man in his forties with a black mustache and ruggedly handsome features. The building has stairs, as the lift is often not working and the electric current is cut off during daylight hours as part of an economy drive. Winston\\'s flat is located on the seventh floor of Victory Mansions. On each landing, there is a poster with a large face that seems to follow you as you move. The caption beneath the poster reads, \"BIG BROTHER IS WATCHING YOU.\"')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Describe Victory Mansions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Created a chunk of size 963, which is longer than the specified 600\n",
      "Created a chunk of size 774, which is longer than the specified 600\n",
      "Created a chunk of size 954, which is longer than the specified 600\n",
      "Created a chunk of size 922, which is longer than the specified 600\n",
      "Created a chunk of size 1168, which is longer than the specified 600\n",
      "Created a chunk of size 821, which is longer than the specified 600\n",
      "Created a chunk of size 700, which is longer than the specified 600\n",
      "Created a chunk of size 745, which is longer than the specified 600\n",
      "Created a chunk of size 735, which is longer than the specified 600\n",
      "Created a chunk of size 1110, which is longer than the specified 600\n",
      "Created a chunk of size 991, which is longer than the specified 600\n",
      "Created a chunk of size 990, which is longer than the specified 600\n",
      "Created a chunk of size 1182, which is longer than the specified 600\n",
      "Created a chunk of size 1491, which is longer than the specified 600\n",
      "Created a chunk of size 1401, which is longer than the specified 600\n",
      "Created a chunk of size 1130, which is longer than the specified 600\n",
      "Created a chunk of size 1326, which is longer than the specified 600\n",
      "Created a chunk of size 1449, which is longer than the specified 600\n",
      "Created a chunk of size 1364, which is longer than the specified 600\n",
      "Created a chunk of size 999, which is longer than the specified 600\n",
      "Created a chunk of size 930, which is longer than the specified 600\n",
      "Created a chunk of size 1022, which is longer than the specified 600\n",
      "Created a chunk of size 1260, which is longer than the specified 600\n",
      "Created a chunk of size 795, which is longer than the specified 600\n",
      "Created a chunk of size 1293, which is longer than the specified 600\n",
      "Created a chunk of size 649, which is longer than the specified 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building located in London that is dwarfed by three other buildings of similar appearance and size. It has three thousand rooms above ground level, as well as corresponding ramifications below. The building has glass doors and upon entering, one can notice gritty dust. Inside, there is a long hallway with a distinct smell of boiled cabbage and old rag mats. At one end of the hallway, there is a large colored poster depicting the face of a ruggedly handsome man in his forties, with a heavy black mustache. The building has seven flights of stairs, as the lift is often not working and the electricity is cut off during daylight hours as part of an economy drive. On each landing, there is a poster with the caption \"BIG BROTHER IS WATCHING YOU,\" and the eyes in the picture seem to follow you as you move.')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "import nltk\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"../.cache\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_one.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim. If there is no relevant text, return : ''\n",
    "            -------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    question = inputs[\"question\"]\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\"context\": doc.page_content, \"question\": question}\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Given the following extracted parts of a long document and a question, create a final answer. \n",
    "            If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "            ------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hojin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Created a chunk of size 963, which is longer than the specified 600\n",
      "Created a chunk of size 774, which is longer than the specified 600\n",
      "Created a chunk of size 954, which is longer than the specified 600\n",
      "Created a chunk of size 922, which is longer than the specified 600\n",
      "Created a chunk of size 1168, which is longer than the specified 600\n",
      "Created a chunk of size 821, which is longer than the specified 600\n",
      "Created a chunk of size 700, which is longer than the specified 600\n",
      "Created a chunk of size 745, which is longer than the specified 600\n",
      "Created a chunk of size 735, which is longer than the specified 600\n",
      "Created a chunk of size 1110, which is longer than the specified 600\n",
      "Created a chunk of size 991, which is longer than the specified 600\n",
      "Created a chunk of size 990, which is longer than the specified 600\n",
      "Created a chunk of size 1182, which is longer than the specified 600\n",
      "Created a chunk of size 1491, which is longer than the specified 600\n",
      "Created a chunk of size 1401, which is longer than the specified 600\n",
      "Created a chunk of size 1130, which is longer than the specified 600\n",
      "Created a chunk of size 1326, which is longer than the specified 600\n",
      "Created a chunk of size 1449, which is longer than the specified 600\n",
      "Created a chunk of size 1364, which is longer than the specified 600\n",
      "Created a chunk of size 999, which is longer than the specified 600\n",
      "Created a chunk of size 930, which is longer than the specified 600\n",
      "Created a chunk of size 1022, which is longer than the specified 600\n",
      "Created a chunk of size 1260, which is longer than the specified 600\n",
      "Created a chunk of size 795, which is longer than the specified 600\n",
      "Created a chunk of size 1293, which is longer than the specified 600\n",
      "Created a chunk of size 649, which is longer than the specified 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There is only one ministry mentioned in the given text, which is the Ministry of Truth.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston will go to work at the Ministry of Truth.')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Where will he go to work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-yIjbGwu1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
